
# ğŸ“„ PDF Q&A Agent

A lightweight **PDF Question-Answering (RAG) Agent** built with **Python, FAISS, and OpenAI models**. It ingests your PDF documents, indexes them into a vector store, and allows you to ask natural language questions with **grounded answers and citations**.

---

## ğŸš€ Features

- ğŸ” **Ingest PDFs** â†’ parses text, chunks, and embeds.
- ğŸ“š **Vector search (FAISS)** â†’ efficient similarity search across documents.
- ğŸ¤– **LLM-powered answers** â†’ grounded in your PDFs, with inline `[citations]`.
- ğŸ–¥ï¸ **Streamlit UI** â†’ ask questions in a simple web interface.
- ğŸ“‘ **Citations** â†’ answers reference original file + page.
- ğŸ› ï¸ **Modular codebase** â†’ extend easily with OCR, rerankers, or custom tools.

---

## ğŸ“‚ Project Structure

pdf-qa/
â”œâ”€ data/
â”‚   â””â”€ pdfs/           # Upload or drop your PDFs here (via UI or manually)
â”œâ”€ store/
â”‚   â””â”€ faiss_index/    # Vector index & metadata (auto-updated after upload)
â”œâ”€ ingest.py           # Ingestion logic (now callable from app)
â”œâ”€ query.py            # CLI Q&A tool
â”œâ”€ app.py              # Streamlit web app (upload, Q&A, auto-ingest)
â”œâ”€ requirements.txt    # Python dependencies
â””â”€ .env                # API keys + config

---

## ğŸ—ï¸ Architecture

1. **Ingest**
   - Parse PDFs with [PyMuPDF](https://pymupdf.readthedocs.io/).
   - Chunk text with overlap.
   - Generate embeddings (`text-embedding-3-large` by default).
   - Store vectors in [FAISS](https://github.com/facebookresearch/faiss).

2. **Query**
   - Embed query â†’ search top-k chunks.
   - Build context block.
   - LLM (`gpt-4o-mini` by default) answers with citations.

3. **Serve**
   - CLI for direct Q&A.
   - Streamlit app for a user-friendly interface.

---

## ğŸ“¦ Repository

[NarimanGardi/pdf-qa-agent](https://github.com/NarimanGardi/pdf-qa-agent)

---

## âš™ï¸ Setup

### 1. Clone repo

```bash
git clone https://github.com/NarimanGardi/pdf-qa-agent.git
cd pdf-qa-agent
```

### 2. Create environment

```bash
python -m venv .venv
source .venv/bin/activate   # Linux/Mac
.venv\Scripts\activate      # Windows
```

### 3. Install dependencies

```bash
pip install -r requirements.txt
```

### 4. Configure API keys

Create `.env`:

```env
OPENAI_API_KEY=sk-...
EMBED_MODEL=text-embedding-3-large
CHAT_MODEL=gpt-4o-mini
```

---

## ğŸ“¥ Ingest PDFs

Drop files in `data/pdfs/`

Run:

```bash
python ingest.py
```

This:

- Parses text
- Chunks and embeds
- Builds FAISS index in `store/faiss_index/`

---

## â“ Ask Questions

### CLI

```bash
python query.py "What does the refund policy say?"
```

Example output:

```
Refunds are available within 30 days [1], but not after product activation [2].

Sources:
[1] Policy.pdf p.4
[2] Policy.pdf p.7
```

### Web App

```bash
streamlit run app.py
```

Open: [http://localhost:8501](http://localhost:8501)

---

## ğŸ›¡ï¸ Tips & Best Practices

- **Chunking** â†’ current: ~900 words w/ overlap. Adjust in `ingest.py`.
- **Citations** â†’ stored per file + page for traceability.
- **OCR** â†’ if PDFs are scanned images, add Tesseract fallback.
- **Cost control** â†’ start with gpt-4o-mini, upgrade only if needed.
- **Security** â†’ never commit your `.env`.

---

## ğŸ”§ Extensions

- ğŸ”„ Swap OpenAI embeddings â†’ `sentence-transformers` for local/offline use.
- ğŸ” Secure UI â†’ add auth middleware or deploy behind a proxy.
- ğŸ“Š Better retrieval â†’ integrate rerankers (e.g., bge-reranker-large).
- ğŸŒ Multi-user â†’ namespace vector stores (one per corpus).
- ğŸ§ª Evals â†’ keep a regression set of Qâ†’expected answer pages.

---

## ğŸ“œ License

MIT License. Use freely, modify, and share.

---

## ğŸ¤ Contributing

PRs welcome! If you build OCR support, UI enhancements, or new chunking strategies, open a PR.

---

## ğŸ§‘â€ğŸ’» Author

Built by Nariman Gardi Â· Software developer & agent builder.

---